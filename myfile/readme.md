# 同济项目报告
读了一个多月，代码基本看完了，虽然其中有一些算法和控制理论还没有学习，但好歹对项目勉强有了点自己的理解。   
同济的代码大部分没有采用ROS依赖，而是通过分的各种层和模块，进行调用集成。  
项目分为四层：tools（工具层），io(硬件层)，tasks（功能层），src（应用层），同时还包括了test测试，相机标定，各种配置文件，可以说是非常非常完整的一个项目了  
我个人认为阅读该项目的顺序应该以src应用层为主轴，通过在阅读src中每个兵种的功能的实现时，去读对应的tasks功能层和io硬件层，这样会有一个更整体的调用的认知，tools文件里的小工具可以当作小甜点，没事读几个  
## tasks
包括自瞄，打符和全向感知
### auto_aim
包括识别器detect/YOLO，分类器classifier，估计器tracker，决策器aimer，坐标转换器solver
#### *****detect/YOLO识别器*****
识别部分包括传统识别和yolo识别
##### 传统识别detect
输入 BGR 彩色图像和帧号，输出最终验证通过的装甲板列表（std::list<Armor>）  

流程大致为:图像预处理，灯条检测与筛选，装甲板匹配（灯条配对），装甲板分类与验证（用到了分类器），重复装甲板去重，以及装甲板的二次矫正（特定区域内的灯条重新检测与匹配，以及可选的灯条顶点 PCA 优化）
##### YOLO识别
项目中包含了很多版本的YOLO模型，并且对每个版本都写了对应的文件.  

输入原始 BGR 图像和帧号，输出最终验证通过的装甲板列表（std::list<Armor>）  

每个版本的yolo流程大致为：图像预处理（裁剪与缩放）；模型推理；结果解析（YOLO11::parse）（将模型输出的原始张量转换为可理解的 “装甲板目标”）；装甲板验证与去重  
#### *****classifier分类器*****
作用是：对已检测到的装甲板区域（ROI，即armor.pattern）进行 “编号识别”，判断装甲板属于哪种类型（如 1 号、2 号、基地等），并输出分类置信度。  

输入Armor对象（需包含有效的装甲板图案pattern），输出分类结果（armor.name编号、armor.confidence置信度）  

流程大致为：输入有效性检查，图像预处理（统一输入格式），模型推理（有OpenCV DNN 推理和OpenVINO 推理，对应不同性能），Softmax 计算（模型原始输出是 “对数分数”，需通过 Softmax 函数转为 “概率置信度”），结果解析（从 Softmax 结果中提取最优分类结果，赋值给Armor对象）
#### *****tracker，target跟踪估计器*****
Target负责单个目标的精细化状态估计（运动建模与滤波），Tracker负责全局的目标管理（选择、跟踪状态控制、多目标协调），共同实现对敌方目标的稳定、可靠跟踪，为自动瞄准提供关键的目标状态支持
Tracker是管理者，Target是被管理的具体对象。。。Tracker中更多的是创建Target实例，应用Target函数
##### tracker
作用是：对检测模块输出的装甲板目标进行持续跟踪、状态管理和优先级决策，结合卡尔曼滤波（EKF）预测与更新、多相机（主相机 + 全向感知相机）数据融合，确保在目标暂时丢失、优先级切换等场景下仍能稳定锁定目标，为后续弹道控制提供连续、可靠的目标信息。

输入：检测结果和时间戳；输出：“跟踪状态” 和 “目标信息”（target）

整体流程
- 1. 构造函数：初始化跟踪参数，从 YAML 配置文件读取跟踪所需的关键参数
- 2. 核心跟踪接口：单 / 多相机目标跟踪
  - 通用预处理（两接口共通）
  - 单相机跟踪(适用于仅主相机输入的场景):状态判断与目标处理,状态机更新,异常检测与输出
  - 多相机融合跟踪(适用于 “主相机 + 全向感知相机” 的场景):全向相机数据读取,状态判断与目标处理(多了主相机和全向相机识别优先级的切换)，状态机更新，结果输出
- 3. 状态机管理：跟踪状态切换：通过found（是否找到目标）和计数变量，实现 5 种状态的自动切换，确保跟踪稳定性
- 4. 目标初始化与更新：EKF 预测与更新（为新检测到的装甲板初始化Target对象，适配不同目标的运动特性）
##### target
作用是：作用是：基于扩展卡尔曼滤波器（EKF）对敌方目标（如旋转的机器人装甲板）的运动状态（位置、速度、角度、角速度等）进行实时估计，通过 “预测 - 更新” 循环实现对动态目标的稳定跟踪，为自动瞄准提供精准的目标状态信息

输入：装甲板信息（Armor）、时间戳、半径、装甲板数量等，时间点（std::chrono::steady_clock::time_point）或时间差（dt），新检测到的Armor对象（含位置、角度、距离等）；；；输出：11 维ekf_.x（位置、速度、角度、角速度等）；armor_xyza_list()返回的所有装甲板预测位置和角度；converged()返回的收敛状态、diverged()返回的发散状态

整体流程：
1. 构造函数：初始化目标与 EKF（Target::Target，两个重载）
   1.  重载 1：Armor对象（初始装甲板观测）、时间戳、旋转半径、装甲板数量、初始协方差对角线；
   2.  重载 2：直接输入位置、角速度、半径、高度等已知参数
2.  预测目标状态：Target::predict（两个重载）
    1. 计算时间差dt（当前时间与上一时刻的差值）；
    2. 定义状态转移矩阵F（11×11）：描述状态变量如何随时间变化（如位置 = 上一位置 + 速度 ×dt）；
    3. 定义过程噪声矩阵Q：基于分段白噪声模型（考虑加速度和角加速度的不确定性），前哨站和普通目标使用不同噪声参数（前哨站更稳定，噪声更小）；
    4. 调用 EKF 的predict方法：用F和Q预测当前状态，并处理角度周期性（限制在[-π, π]）；
    5. 特殊处理：前哨站收敛后限制最大角速度（避免异常值）
3. 更新目标状态：Target::update：用新检测到的Armor数据更新ekf_状态，修正预测误差
   1. 装甲板匹配：观测与预测的装甲板匹配
      1. 生成所有装甲板的预测位置和角度（armor_xyza_list）
      2. 计算观测装甲板与每个预测装甲板的角度误差，选择误差最小的id
   2. 更新 EKF：调用update_ypda方法，基于匹配的id更新滤波器：
      1. 定义观测模型h：将目标状态（旋转中心、角度等）转换为装甲板的观测值（yaw/pitch/distance/angle）
      2. 计算观测雅可比矩阵H（线性化观测模型）
      3. 定义观测噪声矩阵R（基于角度偏差动态调整，偏差越大噪声越大）
      4. 调用 EKF 的update方法：用观测值修正预测状态，处理角度差的周期性
4. 跟踪状态判断：diverged与converged
   1. diverged()：判断跟踪是否发散（状态不可靠）：若目标半径或长短轴长度超出合理范围（0.05~0.5 米），则判定为发散；
   2. converged()：判断跟踪是否收敛（状态稳定）
5. 辅助计算方法
   1.  armor_xyza_list()：生成目标所有装甲板的预测位置（x/y/z）和角度（a），用于匹配新观测
   2.  h_armor_xyz()：根据目标状态和装甲板编号id，计算该装甲板的 3D 坐标（考虑旋转角度和长短轴差异）
   3.  h_jacobian()：计算观测模型的雅可比矩阵（EKF 更新步骤必需，线性化非线性观测关系）
##### EKF调参
EKF（扩展卡尔曼滤波器）的调参核心就是调整你提供的代码中与过程噪声协方差（Q）、观测噪声协方差（R） 以及初始状态协方差（P0） 相关的参数。这些参数直接影响 EKF 的滤波效果（如跟踪稳定性、响应速度、抗噪声能力），是 EKF 调参的核心对象。  
方差：描述 “单个变量” 的波动;方差越小，说明数据越集中在平均值附近
协方差：描述 “两个变量” 的关联.协方差接近0：两个变量几乎没有线性相关关系
- 过程噪声协方差（Q）的参数（影响预测步骤）：target的predict中..v越大，数据可信度越低，更相信新观测
- 观测噪声协方差（R）的参数（影响更新步骤）：target的update_ypda中，R_dig 中的四个元素（分别对应 yaw 角、pitch 角、距离、旋转角的观测噪声方差）。若某一维度的测量误差大，应增大对应 R_dig 元素
- 初始状态协方差（P0）的参数（影响初始收敛）：在tracker的set_target中，若初始状态（如目标初始位置）已知较准确，可减小 P0_dig
#### *****aimer决策器*****
作用：负责根据跟踪模块输出的目标信息，结合弹道物理模型计算最终瞄准角度，为云台控制提供射击指令

输入：目标跟踪数据target，当前时间戳，模式和开关参数（子弹初速度，射击模式，是否基于当时间预测）；输出：瞄准控制指令（io::command）包括是否射击（bool），是否重置云台状态（bool），yaw角和pitch角（控制云台旋转角度）

整体流程：
- 初始化弹道与补偿参数（角度偏移，弹道角度范围，延迟时间等等）
- 计算最终瞄准角度（基础瞄准和考虑射击模式的瞄准（增加 “左右射击模式的角度补偿”））
  - 目标有效性检查，延迟时间与预测时间计算：
    - 根据目标速度（target.ekf_x()[7]）选择延迟时间（高速目标用high_speed_delay_time_，低速用low_speed_delay_time_）
    - 计算子弹飞行总延迟：包含检测 / 跟踪耗时（dt）+ 子弹飞行延迟，得到 “未来预测时间”（future）
    - 调用target.predict(future)预测目标在未来时刻的位置（因子弹飞行需要时间，需瞄准目标 “未来位置” 而非当前位置）
  - 初始瞄准点选择：调用choose_aim_point(target)从目标的多个装甲板中，筛选出 “最可能被命中” 的装甲板（考虑目标旋转、可射击角度范围），得到初始瞄准点（aim_point0）
  - 弹道迭代计算：基于初始瞄准点，用tools::Trajectory计算子弹飞行时间（fly_time）和弹道俯仰角（考虑重力导致的子弹下坠）；迭代优化：因目标在子弹飞行期间会继续运动，需多次预测 “目标在子弹飞行后的位置” 并重新计算弹道，直至飞行时间收敛（相邻两次误差 < 0.001 秒），确保瞄准点与子弹到达时间匹配。
  - 最终角度计算（根据目标点的3D坐标和各种角度补偿，计算yaw和pitch）
-  瞄准点选择，筛选最优装甲板：该函数根据目标运动状态（旋转、速度）选择 “最易命中” 的装甲板
  - 单装甲板处理：若目标未发生装甲板跳变（!target.jumped），直接选择唯一装甲板。
  - 多装甲板角度计算：计算目标旋转中心的偏航角（center_yaw）；计算每个装甲板与旋转中心的角度差（delta_angle_list），反映装甲板相对于中心的位置。
  - 非旋转目标（非小陀螺）
    - 筛选角度差在可射击范围内（<60度）的装甲板
    - 若有多个有效装甲板，进入 “锁定模式”（选择角度差最小的装甲板，避免来回切换）
    - 若仅一个有效装甲板，直接选择并退出锁定模式
  - 旋转目标（小陀螺）：
    - 针对高速旋转的目标，根据旋转方向（ekf_x[7]正负）选择 “即将进入可射击范围” 的装甲板（而非 “即将离开” 的），提高命中概率；
    - 前哨站目标使用单独的角度阈值（70度/30度）。
#### *****solver坐标转换器*****
作用是：通过相机内参、外参和装甲板的图像坐标，计算装甲板在不同坐标系（相机坐标系、云台坐标系、世界坐标系）下的3D 位置、姿态（偏航角 / 俯仰角 / 滚转角）

输入：配置文件参数，IMU姿态数据（下位机传来），装甲板图像信息（Armor）；输出：填充3D信息的Armor，重投影图像坐标，世界3D点的像素坐标

整体流程：
- 1.初始化坐标系与相机参数
- 2.计算装甲板3D信息：先根据装甲板的类型（大或小），PNP解算出旋转和平移矩阵，再通过坐标系的转换，最终求到yaw，pitch，distance
- 3.重投影误差最小化：设定搜索范围，遍历计算重投影误差，选择最优偏航角
#### *****MPC轨迹规划器*****
作用：  
基于模型预测控制（MPC）为云台（yaw/pitch）生成平滑且受约束的角度、角速度与角加速度轨迹（Plan），用于替代直接角度命令以提高跟踪平稳性与命中率。规划器把目标的未来期望角度/速度作为参考，考虑系统动力学、输入/状态约束与代价函数，在线求解有限时域最优控制问题，输出下一步控制与预测轨迹供云台或下位机执行。

输入：
- 跟踪模块输出的 `Target`（目标角度、角速度、预测态）或短期 `Trajectory`（期望 yaw/pitch 的时间序列）；
- 当前云台状态（yaw/pitch、速度、时间戳），通常由 IO 层（云台反馈）提供；
- 子弹速度、延迟补偿等弹道参数（用于把目标位置转为参考角度）；
- MPC 配置（预测步长 N、采样时间 dt、权重矩阵 Q/R、输入/状态上下界、ADMM 求解器参数 rho/tol/max_iter），来自配置文件或 codegen 导出的静态数据；
- （可选）上一次解作为 warm-start。

输出：
- `auto_aim::Plan`：包含控制开关（control）、开火标志（fire）、目标角度 `target_yaw/target_pitch`，以及 yaw/pitch 在多个时刻的 position/velocity/acceleration（用于云台平滑跟随或下位机执行）；
- 求解器诊断信息（迭代次数、收敛/失败标志、残差），用于日志与回退策略。

实现文件（位于 `tasks/auto_aim/planner`）：
- `planner.hpp` / `planner.cpp`：高层 `Planner` 类，维护 `yaw`/`pitch` 两个 `TinySolver` 实例，负责将 `Target`/`Trajectory` 转换为 MPC 问题、调用求解器并组装 `Plan`；
- `tinympc/`：轻量级 MPC 内核（ADMM 实现）
  - `tiny_api.hpp` / `tiny_api.cpp`：对外 C 风格接口（如 `tiny_setup`、`tiny_set_x_ref`、`tiny_set_u_ref`、`tiny_solve`、`tiny_get_solution` 等）；
  - `types.hpp`：solver、solution、settings 与缓存等数据结构定义；
  - `admm.cpp`：ADMM 求解器核心循环；
  - `rho_benchmark.*`：自适应 rho 的估计与矩阵更新工具；
  - `codegen.*`：将预计算矩阵导出为静态 C++ 数据的工具（便于嵌入式部署）。

典型流程（`Planner::plan` 的执行步骤）：
1. 参考轨迹生成／预处理  
  - 将输入的 `Target` 或 `aim` 结果转换为短期参考轨迹（位置/速度/加速度），长度为预测步数 N（`get_trajectory`）。
2. 构建离散系统与 MPC 问题数据  
  - 设置离散动力学矩阵 A/B、状态维度 nx、输入维度 nu、初始状态 x0、权重 Q/R、约束 x_min/x_max/u_min/u_max、采样时间 dt 等（构造时或从 codegen 加载）。
3. 将数据通过 tinympc API 传入求解器  
  - 调用 `tiny_set_x_ref` / `tiny_set_u_ref` / `tiny_set_bounds` / `tiny_set_initial_state` 等接口；若启用 warm-start，则写入上一次解。 
4. 调用求解器求解  
  - 调用 `tiny_solve`（内部运行 ADMM），迭代至收敛或达到 `max_iter`。若启用自适应 rho，会在迭代间调整 rho 并更新缓存。 
5. 提取结果并封装  
  - 从 `TinySolution` 中读取最优状态/控制序列，取首步控制或首时刻的 pos/vel/acc 填充 `auto_aim::Plan`；记录求解器状态供上层决策。 
6. 失败/降级策略  
  - 若求解失败或未收敛，返回退化策略（例如直接返回 `aim` 角度、使用简单 PD 控制或保持上一命令），并写入诊断日志。

集成与运行上下文：
- 在 `src/standard_mpc` 等应用中，会启动独立的 MPC 线程：该线程从 target 队列读取最新 `Target` 与当前云台状态，调用 `Planner::plan` 生成 `Plan`，并通过 IO 层或命令生成模块将 `Plan` 下发给云台或下位机；主线程负责相机采集、检测与 Tracker 管理。 
- 当前实现通常为轴分离的两个独立求解器（`yaw_solver_`、`pitch_solver_`）；也可扩展为联合状态的单一求解器以处理耦合。 

可配置项与需调参的关键参数：
- 预测步数 N 与采样时间 dt（影响预测能力与计算量）；
- 权重矩阵 Q（跟踪误差）与 R（控制量）；
- 输入/状态约束（转速/加速度上限）；
- ADMM 参数：rho、tol、max_iter、是否启用自适应 rho；
- 是否启用 warm-start、是否使用 `codegen` 常量化矩阵以减少在线开销。

调试建议与常见问题：
- 可视化参考轨迹 `X_ref/U_ref` 与解出的 `x/u` 以定位模型不匹配或权重设置问题；
- 若常不收敛，尝试调整 rho、放宽 tol、增加 max_iter 或启用 warm-start；
- 若实时性不足，可减小 N、使用 `codegen` 静态矩阵或关闭自适应 rho；
- 实现失败回退（保持上一命令或使用 PID）以避免云台突跳；
- 部署到嵌入式设备时优先使用 `codegen` 导出的常量并减少在线矩阵组装。 

关键文件定位（便于后续修改）：
- `tasks/auto_aim/planner/planner.hpp` / `planner.cpp`（Planner 高层逻辑）；
- `tasks/auto_aim/planner/tinympc/tiny_api.hpp` / `.cpp`、`admm.cpp`、`types.hpp`（MPC 内核）；

小结：  
MPC 轨迹规划器把目标预测、系统动力学、约束与代价整合为有限时域最优控制问题，通过 `tinympc`（基于 ADMM）在线求解，输出平滑的角度/速度/加速度轨迹。主要调参点在模型匹配（A/B）、权重与约束、ADMM 的 rho/tol，以及实时性优化（N、codegen、warm-start）。
### auto_buff
包括识别器detect，估计器target，决策器aimer，坐标转换器solver
#### 识别器
作用是：从输入图像中检测旋转的能量机关扇叶，计算其旋转中心和状态，为后续跟踪和打击提供关键目标信息

输入：配置参数，图像；输出：能量机关状态

整体流程：
- 初始化检测状态与YOLO模型；
- 图像预处理：增强扇叶特征；
- 旋转中心计算：定位能量机关中心（根据YOLO检测到的扇叶特征点，计算能量机关的旋转中心（r_center））
    - 这里旋转中心的寻找挺巧妙的，先遍历扇叶，再利用扇叶特征点结合经验公式求出大致中心，
    - 又利用这个大致中心，生成圆形掩码，最后对预处理后的图像应用这个掩码，再求被掩码处理后的精确图像的轮廓和每个轮廓的最小外接矩阵，
    - 再通过 “矩形长宽比” 和 “与初始中心的距离” 综合评分（ratio），选择评分最低的矩形中心作为最终旋转中心
- 能量机关状态生成：创建PowerRune对象（封装扇叶列表、旋转中心、历史状态last_powerrune_）
- 状态管理：
    - 若检测成功且PowerRune有效：更新状态为TRACK，重置丢失计数lose_，记录当前状态到last_powerrune_；
    - 若检测失败或PowerRune无效：调用handle_lose（丢失计数 + 1，超过LOSE_MAX则状态设为LOSE）。
#### 估计器
作用是：基于检测模块输出的能量机关状态（PowerRune），通过扩展卡尔曼滤波实现对 “小符” 和 “大符” 的连续状态估计（位置、旋转角度、角速度等），并通过投票器判断旋转方向、处理跟踪发散，为后续瞄准模块提供稳定的目标未来状态预测

输入：时间戳，Powerrune，配置参数；输出：跟踪状态，EKF状态，旋转方向，调式日志

整体代码流程：
- 1. 旋转方向判断voter类：通过多帧角度差投票来判断旋转方向
- 2. Target类（为为子类（SmallTarget/BigTarget）提供接口）：坐标系转换，状态判断(能否跟踪)，EKF状态获取
- 3. SmallTarget类（小符）
    - 1. 初始化EKF状态向量和协方差矩阵
    - 2. 状态预测：predict(double dt)基于时间差（dt）预测目标下一帧状态，核心是构建 EKF 的状态转移矩阵（A_）和过程噪声矩阵（Q_）
    - 3. 状态更新：update(double nowtime, const PowerRune & p)，基于新检测到的PowerRune数据，分两次 EKF 更新修正状态（分别融合 “能量机关整体状态” 和 “扇叶中心状态”）
      - 第一次更新（能量机关整体状态）：
        - 观测向量（z1）：从PowerRune提取R_ypd（偏航 / 俯仰 / 距离）和ypr[2]（横滚角），即z1 = [R_ypd[0], R_ypd[1], R_ypd[2], ypr[2]]；
        - 观测矩阵（H1）：4×7 矩阵，仅选择与观测向量对应的 EKF 状态维度（如R_yaw对应H1(0,0)=1）；
        - 观测噪声（R1）：对角矩阵，对 “偏航 / 俯仰” 设较小噪声（0.01），对 “距离” 设较大噪声（0.5），对 “横滚角” 设中等噪声（0.1）；
        - 角度差处理：z_subtract1函数确保观测值与预测值的角度差在[-π, π]范围内；
        - 调用ekf_.update(z1, H1, R1, z_subtract1)完成第一次更新
      - 第二次更新（扇叶中心状态）：
        - 观测向量（z2）：从PowerRune提取扇叶中心的B_ypd（偏航 / 俯仰 / 距离），即z2 = [B_ypd[0], B_ypd[1], B_ypd[2]]；
        - 观测矩阵（H2）：通过h_jacobian()计算，反映 “EKF 状态→扇叶中心 YPD” 的非线性关系（基于坐标系转换的雅可比矩阵）；
        - 观测函数（h2）：将 EKF 状态转换为扇叶中心的 YPD（先转 XYZ，再转 YPD）；
        - 调用ekf_.update(z2, H2, R2, h2, z_subtract2)完成第二次更新。
      - 扇叶跳变处理：若当前横滚角（ypr[2]）与 EKF 预测值（ekf_.x[5]）差值超过π/12，则遍历i∈[-5,5]，找到ekf_.x[5] + i*2π/5（5 为扇叶数量）与ypr[2]差值最小的角度，修正 EKF 状态，避免扇叶跳变导致跟踪中断。
    - 4.  跟踪控制：get_target(const std::optional<PowerRune> & p, std::chrono::steady_clock::time_point & timestamp)
      - 未检测到目标：若p为空（!p.has_value()），unsolvable_=true，丢失计数（lost_cn）+1；
      - 首次检测：若first_in_=true，调用init初始化 EKF，first_in_=false；
      - 丢失处理：若lost_cn > 6（连续 6 帧未检测到），标记unsolvable_=true，重置first_in_=true，重新等待初始化；
      - 发散判断：若 EKF 角速度（ekf_.x[6]）超出[SMALL_W - π/18, SMALL_W + π/18]（SMALL_W为小符默认角速度），标记unsolvable_=true，重置first_in_=true，避免发散跟踪。
- 4. 大符：BigTarget类(正弦变速旋转)
    - 1. 状态向量差异（10 维）x0_ = [R_yaw, v_R_yaw, R_pitch, R_dis, yaw, angle/row, spd, a, w, fi] 新增 3 个维度：
      - a：变速运动的振幅（对应正弦速度的幅度）；
      - w：变速运动的角频率（对应正弦速度的周期）；
      - fi：变速运动的初相位（对应正弦速度的起始相位）；
      - 初始值基于大符常见运动参数设置（如a=0.9125、w=1.942）
    - 2. 状态预测差异：predict(double dt)
      - 状态转移函数（f）：横滚角（x_prior[5]）的预测考虑正弦速度：x_prior[5] = angle_prev + voter.clockwise() * ( -a/w*cos(w*t+fi) + a/w*cos(w*t_prev+fi) + (2.09 -a)*dt )；
      - 过程噪声矩阵（Q_）：新增对 “横滚角”（0.09）、“角速度”（0.5）、“初相位”（1.0）的噪声设置，适配变速运动的不确定性。
    - 3. 速度拟合：spd_fitter_(应用了工具层的正弦拟合函数)
      - 数据采集：spd_fitter_.add_data(nowtime, ekf_.x[6])，将 EKF 输出的角速度（ekf_.x[6]）和时间戳（nowtime）加入拟合数据；
      - 正弦拟合：spd_fitter_.fit()，通过最小二乘法拟合角速度的正弦模型（spd = A*sin(omega*t + phi) + C）
      - 拟合输出：spd_fitter_.sine_function(...)，用拟合后的参数预测当前角速度（fit_spd_），用于修正 EKF 的速度状态
    - 4. 发散判断差异
      - 大符发散判断基于新增的变速参数：若ekf_.x[7]（a）超出[0.78/1.5, 1.045*1.5]，或ekf_.x[8]（w）超出[1.884/1.5, 2.0*1.5]，则标记发散，重置跟踪
#### 决策器
作用是：基于跟踪模块输出的能量机关状态（Target），结合弹道模型计算瞄准角度和射击时机，生成云台控制指令（io::Command）和模型预测控制（MPC）计划（auto_aim::Plan）

输入有配置参数，跟踪目标，时间戳，子弹速度，是否基于当前时间预测，云台状态（MPC接口用；输出有：command，MPC计划Plan

整体代码流程
- 1. 初始化配置参数
- 2. 生成基础控制指令（main）
    - 检查目标有效性
    - 子弹速度处理
    - 计算预测时间：总预测时间 = 延迟补偿 + 基础预测时间，若to_now=true则直接使用该值，否则固定为0.1 + predict_time_
    - 计算瞄准角度（调用get_send_angle）
    - 生成控制指令
      -  角度稳定性判断：若当前角度与上次角度差超过 5°（转换为弧度），标记角度跳变，累加误差计数（mistake_count_）
      -  控制逻辑：若误差计数 > 3：强制切换扇叶瞄准（switch_fanblade_=true），重置计数，允许云台控制；若角度跳变：标记切换扇叶，计数 + 1，禁止云台控制；若角度稳定：重置计数，允许云台控制；
      -  射击逻辑：若切换扇叶：禁止射击，更新上次射击时间；若角度稳定且距离上次射击超过fire_gap_time_：允许射击，更新上次射击时间
- 3. 核心角度计算：Aimer::get_send_angle（根据目标未来位置和弹道模型，计算最终瞄准角度，采用 “二次预测 + 弹道迭代” 提高精度）
    - 第一次目标预测：基于predict_time预测目标未来位置，调用target.predict(predict_time)更新目标状态
    - 第一次弹道解算
      -  计算目标点在世界坐标系的坐标（aim_in_world）
      -  提取距离（d，水平距离）和高度（h，垂直距离）
      -  创建弹道对象（trajectory0）：输入子弹速度、d、h，解算飞行时间（fly_time）和俯仰角，若解算失败返回false
    -  第二次目标预测：基于第一次弹道的飞行时间（trajectory0.fly_time）再次预测目标位置，补偿子弹飞行期间的目标运动（能量机关旋转导致位置变化）
    -  第二次弹道解算：重新计算目标点坐标、d、h，创建弹道对象（trajectory1），解算飞行时间和俯仰角，若失败返回false。
    - 时间误差校验：若两次弹道飞行时间差（time_error）>0.01 秒，说明预测不稳定，返回false
    - 角度修正与输出：计算yaw和pitch角
- 4. MPC 瞄准接口：生成带速度 / 加速度的计划（Aimer::mpc_aim）：在常规瞄准基础上，增加模型预测控制（MPC）的速度和加速度规划，用于更平滑的云台控制
    - 速度与加速度计算：首次进入 MPC 模式（first_in_aimer_=true）：速度和加速度设为 0；非首次：速度：基于当前与上一帧预测角度差除以时间（2*dt）计算，加速度：基于角度变化率的二阶导数计算
    - 控制逻辑适配：与aim函数类似，但将 “云台控制” 扩展为 “MPC 计划生成”，确保云台运动更稳定
#### 坐标转换器
作用是：基于相机采集的图像特征和预设的 3D 模型点，通过PnP算法解算能量机关在世界坐标系中的位姿，并完成 “相机→云台→世界” 的多坐标系转换，为后续跟踪和瞄准模块提供精准的 3D 空间信息

输入：配置参数，IMU四元数，图像2D点，3D模型点；输出：世界系位姿，YPD参数，扇叶位置，欧拉角姿态，重投影点

代码流程：
- 1. 3D 模型特征点生成：用第一个扇叶的 3D 基础点结合角度求出其它扇叶
- 2. 多坐标系参数初始化：加载坐标系转换参数，相机内参和畸变系数，世界系旋转矩阵
- 3. 世界系旋转矩阵更新：set_R_gimbal2world
- 4. 位姿解算：PNP解算求位姿，再坐标系变换，再位姿参数变换一下（XYZ到YPD和欧拉角）
- 5. 重投影辅助调试
### omniperception
感知器perception，决策器decider
#### 感知器
作用是：通过 4 个 USB 相机并行采集图像，利用 YOLO 模型同时进行目标检测，并将检测结果汇总到线程安全队列，为上层决策提供多视角的实时感知数据

输入：相机设备，配置参数；输出：检测结果队列

代码流程：
- 1. 初始化多相机与并行检测资源：创建线程安全队列（tools里有）；初始化决策器；为每个相机创建独立的 YOLO 检测模型，避免多线程竞争；启动 4 个并行推理线程（每个线程绑定一个parallel_infer函数，分别处理一个相机的图像）
- 2. 并行推理线程：多相机实时检测
    - 1. 线程退出检查：循环中通过stop_flag_判断是否需要退出（结合互斥锁mutex_确保线程安全）
    - 2. 调用相机的read方法获取图像（usb_img）和时间戳（ts），若图像为空（采集失败），休眠 30ms 后重试
    - 3. 调用当前线程绑定的 YOLO 模型（yolov8_parallel->detect）检测图像中的目标（如装甲板），返回armors（目标列表）
    - 4. 若检测到目标（armors非空），通过decider_.delta_angle计算目标相对于相机的角度偏差（偏航角delta_yaw、俯仰角delta_pitch），并转换为弧度（除以 57.3）
    - 5. 将目标列表、时间戳、角度偏差封装为DetectionResult，推入detection_queue_，供上层模块读取
- 3.  结果获取接口：Perceptron::get_detection_queue：循环弹出队列中的DetectionResult，直到队列为空，返回汇总后的结果列表（std::vector<DetectionResult>）
- 4. 析构函数：线程安全退出（Perceptron::~Perceptron）
  - 1.  加锁设置stop_flag_ = true，通知所有线程退出
  - 2. 唤醒所有等待的线程（condition_.notify_all()）；
  - 3. 等待所有线程执行完毕（t.join()），确保资源正确释放
#### 决策器
作用是：基于多相机检测的装甲板结果，进行目标筛选（过滤无敌、非敌方装甲）、优先级排序，并计算目标相对于相机的角度偏差，最终生成云台控制指令

输入：std::list<auto_aim::Armor>装甲板列表，相机图像，云台状态，外部指令（无敌装甲 ID、指定瞄准目标	来自ROS2），配置参数；输出：控制指令，目标信息

代码流程：
- 1. 初始化配置与依赖
- 2. 多相机决策接口：Decider::decide（多重载）
    - 1. 多 USB 相机决策（decide接收usbcam1~2和back_camera）
      - 1. 按轮询顺序（count_控制）读取相机图像，调用YOLO检测装甲板
      - 2. 筛选有校装甲板（过滤无敌，非敌方），若检测到有校装甲板就计算角度偏差，生成控制指令
      - 3. 轮询计数count_自增，切换下一个相机
    - 2.  后置相机决策（decide接收back_camera）
      - 1.  读取后置相机图像
      - 2.  检测并筛选装甲板，计算角度偏差，生成控制指令
      - 3. 无有效装甲则返回空指令
    - 3. 检测结果队列决策（decide接收detection_queue）
      -  若队列为空，返回空指令
      -  取队列首个有效结果，生成控制指令（直接使用预计算的角度偏差delta_yaw/delta_pitch）
- 3. 关于上面装甲板的筛选：
    - 1. 过滤非敌方颜色的装甲板（a.color != enemy_color_）
    - 2. 过滤特定类型装甲（如 25 赛季无 5 号装甲，过滤ArmorName::five；过滤工程、前哨站装甲）
    - 3. 过滤无敌状态的装甲板（invincible_armor_列表）
- 4. 关于上面角度偏差的计算：根据相机类型（左 / 右 / 后置），计算装甲板中心相对于相机的角度偏差（偏航delta_yaw、俯仰delta_pitch）
- 5. 优先级与排序：Decider::set_priority/Decider::sort
  - set_priority：根据工作模式（mode_），从优先级映射（mode1/mode2）中获取装甲板优先级，赋值给Armor::priority
  - sort：对每个DetectionResult中的装甲板，先筛选再按优先级排序；对所有DetectionResult按装甲板优先级排序，确保高优先级结果优先处理
- 6. 辅助功能：get_invincible_armor从外部接收无敌装甲 ID 列表，更新invincible_armor_；get_auto_aim_target 从外部接收指定瞄准的装甲类型，过滤装甲板列表，仅保留指定类型。
## io
硬件抽象层有相机（海康，迈德威视的SDK，相机基类，USB相机），下位机（云台，serial库），IMU，ROS2，socketcan
### 相机
#### 相机基类
1. 根据配置初始化相机（Camera::Camera(const std::string & config_path)），读取相机通用参数
2. 根据相机品牌初始化相机实例
3. read函数读取相机的图像和时间戳
#### USB相机
1. USBCamera() 初始化成员变量，调用try_open()，创建守护线程
2. tryopen() 再调用open() :设备路径拼接与连接，相机参数配置，通过sharpness_判断左右相机，启动取图线程，加互斥锁保护cap_, read图像，成功就将图像和时间戳（当下时间）写入队列queue_
3. read() 重载函数，1：简单读取单帧图像，直接从cap_读取；2：带时间戳读取图像，从queue_取出数据使用
### 下位机
#### 云台
1. 初始化，加载串口配置，初始化并打开串口（调用serial_.setPort(com_port)设置串口端口，try serial_.open()打开串口），启动姿态读取线程（创建thread_线程，绑定read_thread成员函数），调用queue_.pop()弹出队列首个姿态数据
2. read_thread() 循环读取与处理 
  1.  处理异常（！read）：错误重连判断，读取帧头，读取剩余数据，，，CRC16校验（调用tools）
  2.  处理有效数据，记录时间戳；解析姿态四元数：从rx_data_.q（数组）构造Eigen::Quaterniond，与时间戳t一起存入queue_；
  3.  加互斥锁（std::lock_guard），将rx_data_中的姿态（yaw/pitch）、角速度、子弹速度、子弹数量赋值给state_
  4.  更新云台模式：根据rx_data_.mode（0/1/2/3）转换为GimbalMode
3. 上层调用send()重载函数，通过结构体或参数列表发送，将传经来的参数赋值给tx_data_，再将tx_data_ write进serial
4. 获取时间对齐的姿态，上层调用q(t)  ，，，因为云台反馈的姿态是离散的，所以要通过队列的前后帧，计算时间差与插值系数，通过SLERP插值，加上时间范围的判断，最终返回对齐姿态（挺抽象的，没细研究。。。
5. reconnect()成员函数 重连参数初始化，循环重试连接，重试结束
6. 析构函数  quit_=true，若thread_.joinable()（线程未回收），调用thread_.join()等待线程安全终止，关闭串口：调用serial_.close()释放串口资源，避免端口占用
### 达妙IMU
1. 初始化，队列初始化（容量5000），串口初始化化init_serial()成员函数，绑定get_imu_data_thread成员函数，从queue_中弹出前两帧数据，分别存入data_ahead_和data_behind_，初始化完成
2. init_serial()成员函数，对serial_的各种成员变量赋值传参
3. get_imu_data_thread成员函数 
   1.  串口状态检查（!serial_.isOpen()）
   2.  读取帧头并校验，读取 4 字节帧头数据到receive_data.FrameHeader1；
      校验帧头是否符合协议：FrameHeader1 == 0x55、flag1 == 0xAA等等
   3. 读取剩余数据
   4. CRC16 校验与数据解析，先校验CRC16，再将每个部分（加速度，角速度，欧拉角）读到data
   5. 姿态转换，将data的欧拉角到四元数，然后归一化，再存入queue_
4. 时间对齐的姿态查询（上层调用imu_at(timestamp)）。。。。和上面一样，离散帧，插值系数，SLERP插值
5. 析构函数  不要忘了回收线程，关闭串口喵~
### ROS2
1. publish发布（功能封装类）
   1. 构造函数，创建ROS2节点，初始化发布者
   2. 数据发布接口：Publish2Nav::send_data：将目标位置(target_pos)数据转换为字符串消息并发布
   3. 启动节点循环：Publish2Nav::start；输出日志，spin循环节点事件
   4. 析构：输出日志
2. subscribe订阅（功能封装类
   1. 初始化ROS2节点与订阅者：创建 ROS2 节点，初始化订阅者、队列、计数器和定时器
   2. 消息回调函数：处理接受的消息（enemy_status_callback/autoaim_target_callback）
       1.  清空enemy_statue_queue_（只保留最新消息），将新消息msg存入队列
       2.  计数器enemy_status_counter_自增（记录收到的消息数）
       3.  若收到至少 2 条消息，取消旧定时器（若存在），创建新定时器：1.5 秒后清空队列和计数器（避免长期无新消息时使用旧数据）
       4. 同理，  autoaim_target_callback处理autoaim_target话题的消息，逻辑一致
   3. 启动spin循环，并且输出日志
   4. 消息读取接口：供其他模块获取数据（subscribe_enemy_status/subscribe_autoaim_target）：主要是从队列中取出最新消息（back(msg)），输出接收日志（含时间戳），返回消息中的invincible_enemy_ids（无敌敌方装甲板 ID 列表），另一个同理，返回自瞄的目标
   5. 析构：输出关闭日志，提示节点已停止
3. ROS2（通过统一接口对外提供 ROS2 通信功能，发布目标信息、订阅敌方状态等）
整体是，输入给他目标位置的数据，然后他会发布给导航模块，然后再订阅导航模块的敌方无敌 ID 列表和指定瞄准目标 ID 列表
   1.  构造函数：初始化 ROS2 与通信组件（ROS2::ROS2）：
       1.   调用rclcpp::init(0, nullptr)初始化 ROS2 环境（无命令行参数）
       2.   创建发布者实例publish2nav_，创建订阅者实例subscribe2nav_
       3.   启动两个独立线程publish_spin_thread_：执行publish2nav_->start()，启动发布者节点的事件循环（rclcpp::spin）；subscribe_spin_thread_：执行subscribe2nav_->start()，启动订阅者节点的事件循环
    2. 对外接口：封装发布与订阅功能
       1.  publish方法：向导航模块发布目标位置信息；
       2.  subscribe_enemy_status方法：获取导航模块发布的 “敌方无敌状态 ID 列表”；
       3.  subscribe_autoaim_target方法：获取导航模块发布的 “指定瞄准目标 ID 列表
### socketcan
（这个我是真不会  
这是Linux 系统下 CAN 总线通信的封装类（io::SocketCAN），核心作用是：通过 SocketCAN 接口实现 CAN 总线的数据收发，同时提供自动重连机制和异步接收处理
1. 构造函数：初始化连接与线程（SocketCAN::SocketCAN）
   1.  初始化成员变量（ socket 描述符为 - 1、退出标志quit_为false
   2.  调用try_open()尝试打开 CAN 接口
   3.  启动守护线程（daemon_thread_）：循环检查连接状态（ok_），若连接断开（ok_为false），则等待接收线程结束，关闭旧连接，重新调用try_open()建立连接（确保通信中断后自动恢复）
2. try_open:调用open()，失败就输出失败日志。open（）：看不懂。。。。。这是电控的吧~？
   1.  调用socket(PF_CAN, SOCK_RAW, CAN_RAW)创建 RAW CAN 套接字（socket_fd_）
   2. 通过ioctl获取 CAN 接口的索引（绑定硬件接口），调用bind将套接字绑定到指定 CAN 接口
   3. 创建 epoll 实例（epoll_fd_），将 CAN 套接字添加到 epoll 监听列表（关注EPOLLIN事件，即有数据可读）
   4. 启动接收线程（read_thread_）：循环通过 epoll 等待 CAN 消息，读取后调用rx_handler_回调函数处理
3. 消息接收：SocketCAN::read()
   1. 调用epoll_wait等待事件（超时时间 2ms），获取就绪的事件数量（num_events）
   2. 对每个就绪事件，调用recv读取 CAN 帧（can_frame），若读取失败则抛出异常（触发连接重连）
   3. 调用上层传入的rx_handler_回调函数，将接收到的can_frame传递给上层模块处理 
4. 消息发送：SocketCAN::write(): 向 CAN 总线发送数据帧,调用 Linux 系统调用::write将 CAN 帧写入套接字，若失败则抛出std::runtime_error
5. 析构：设置quit_为true，等待守护线程和接收线程执行完毕（join()）；调用close()关闭 epoll 和套接字描述符，释放系统资源
## src
应用层更多的是将功能集成起来，该项目的应用层中包括调试，多线程等各种
### standard
#### standard 标准机器人的流程（只有自瞄）
- 1. 先初始化各种tools，io层的相机，C板，以及tasks的自瞄的功能器，机器的mode等
- 2. 再在!exiter.exit()的条件下，获得相机的图像，IMU的姿态，机器人的mode
- 3. 然后就是经典流程：坐标解算，识别器识别到装甲板，估计器估计出含跟踪状态和各种目标信息的targets，决策器Aimer算出command，C板发出command
#### mt_standard 加上多线程和打符后
 初始化各种各种，注意此处自瞄的检测器初始的是多线程下的检测器，开一个视觉检测线程（只在自瞄下工作），主线程，当为自瞄时，就先从detect获得img，armor，t，再经典流程：坐标解算与目标跟踪，指令生成与发送（自瞄多线程的指令发生用的是在tasks的多线程下写的commandgener），当mode为打符时，也是先获得相机的图像，IMU姿态，，检测符，坐标解算，mode判断大符小符，跟踪目标获得targets，aimer生成command，c板发出command
#### standard_mpc 再加上mpc轨迹控制后
不同的是command不再由aimer生成，而是改成MPC的Planner生成计算好的云台应该运动的Plan，然后将Plan发给云台  
初始化各种，开一个mpc规划的线程，该线程只用于自瞄，该线程的作用，从target队列不断获得最新的target，然后获得云台的姿态，通过MPC规划计算出云台要运动的plan，然后将plan发给云台。主线程为：获得相机的图像、云台姿态，当为自瞄模式时，用yolo检测得到装甲板，tracker跟踪获得目标target，然后将target传入目标队列，让mpc规划线程用；打符模式为检测目标，解算目标姿态，判断符的mode，跟踪估计目标，然后再用打符里的mpc_aim获得buff_plan，最后再发给云台
### sentry
烧饼不同于标准机器人的是（无人控制）：要用ROS2订阅敌方机器人的状态；要自己选择攻击装甲板的策略；主相机找不到敌方目标的时候，要用decide结合多相机寻找决策；发射时，要自己解算判断是否发射
#### sentry标准烧饼
1. 初始化各种工具参数，初始化四路相机，ROS2通信
2. 先用主相机读取的图像，yolo检测装甲板，再用ros2接受到敌方装甲板的状态，进行一个过滤，然后对过滤后的目标设立优先级，然后跟踪估计track目标，再对track的状态进行一个判断，如果跟踪状态是lost，就采用烧饼的多个相机全向感知，进行决策，如果跟踪成功，就用常规aimer获得command，再用shooter，根据目标状态等，判断是否发射，更新command的发射判断（true or false），最后将command发给c板，用ros2发布要攻打的目标的信息
#### sentry_multithread(多线程？)
不同的时，标准的烧饼以主相机检测到的为主，主相机没有检测跟踪到target，再调用全向感知决策。而这个是在主相机检测的同时全向感知获得全向的检测目标队列，并且对队列排序，然后在跟踪和状态估计的时候，同时传入了主相机检测到的和全向感知检测到的，输出当前稳定跟踪的目标列表，和从全向检测队列中筛选的最优目标，然后再判断发射上加了一个跟踪器状态的判断，当处于switching停止发射，避免切换时误击。并且增加了对command的角度的限制，限定云台yaw和pitch的角度  
是被动补盲到主动融合，新增了对目标切换状态的处理
#### sentry_bp
区别是只有两相机？
### uav
流程和strand差不多，初始化，自瞄，打符，不一样的是，无人机的command多了horizon_distance
## 感想
好大的项目，写完报告还是感觉好复杂（可能考虑太多了，实际上把每个模块、每个工具的内部内容写好，模块的参数的考虑好，模块与模块之间的参统一，在应用时，用各种模块的功能，整体流程还是很顺的。。  

尽可能具象化一下谈谈我的理解  
每个兵种的视觉项目像一颗大树，树干在那里，你要做的是对这个树干添枝加叶，让他尽可能的茂盛  
1. 像一颗树，你想好要造的枝条（每个应用）有什么（自瞄，打符，全向感知...），考虑好不同的树要用什么枝条（像烧饼要多全向感知），将枝条挂到这个树干上。  
2. 树的枝条
   1. 考虑每个枝条（应用层）上要有什么叶子：好比要实现自瞄这个枝条，要有识别器，分类器等等这些枝条上的叶子
   2. 叶子怎么挂：要实现自瞄，要先识别，分类，估计等等...按顺序走
   3. 什么时候用树干上的这个枝条：我打符用打符档，自瞄要自瞄档...
3. 枝条上的叶子
   1. 每个叶子如何合理正好完美的挂到枝条上:每个器实现一个功能，那这个功能的输入输出是什么，输入的要匹配上已有的，输出的要匹配给接下来要用的，要保证整体流程不会出现驴头不对马嘴的情况，好比，我用了识别器是用了输入的：相机拍的图像，要输出：我识别器识别的装甲板armors，好，现在我识别器输出了armors，就能按着枝条上的流程顺序走，我的armors可以匹配给tracker，然后我的tracker又输出了target，然后后面种种，target给aimer，aimer再输出command......最最后输出的就能完成这个枝条的作用
   2. 然后再考虑每个叶子具体长什么样: 每个器的内部的功能怎么实现的，用各种函数，各种算法...
4. 因为很多叶子里用到了同样的东西，在每个叶子里都写一遍太麻烦，所以将这些常用的东西写成了果子（tools），有叶子用的时候直接镶嵌上去打包好的果子就可以了
5. 这颗树不是空中楼阁，他要在地面（硬件）扎根，与地面交流，所以我们还要对这个树进行加工，让他能与地面更好的对口交流
   1. 像我们要把我们的产物传给地面，所以我们要与地面交流，这就用到了io硬件层，像我们把我们产生的command传给c板
   2. 我们也要从地面获得养分（传来的数据，像图像，IMU姿态...），在产生我们的产物时，我们会去用到这些养分（识别要用到相机传来的图像，决策要考虑云台姿态...），而这些都在我们创造叶子的时候完成了对养分的处理利用的流程的编写
6. 那么整体的流程就是，地面说我想要什么什么（指令），并且给你传了（用io硬件层）一堆东西（硬件方面输入的数据），那么你按照地面的要求（我要自瞄，我要打符...），利用地面给你的养分（输入的数据,图像，姿态...），去找可以完成地面要求的枝条（应用，自瞄打符...），然后按照枝条上的叶子(每个器..识别器，估计器....)，一步步去产生地面要的东西（command），并且传输（用io硬件层）给地面
7. 如果我们要对这颗树改进优化，无论是想加一个枝条这种大改动，还是具体到某个叶子的某个函数的改动，只要我们清楚整体的结构流程，定位到我们要改动的点，写好要迭代的部分，并且做好要迭代的部分的输入输出的匹配（使其能够与整个树的流程相匹配契合），就可以实现在整个大树上不断的优化迭代改进

同济项目报告大体就这些了，别的不太重要或者好理解的就没写，然后MPC规划也没写，后面有空搞懂再慢慢补吧，这个报告的初衷更多的是在我细致的读过各种内部代码过后，帮我理一遍整体的框架和流程，以及后面要用同济的代码的话，可以更快的定位一些具体的函数功能之类的
## 反刍
### 重投影：关于为什么auto_aim_test有这么多重投影的框
1. 通过YOLO识别一帧图像，然后YOLO回返回一个outputs，再通过outputs向量获得Armor，里面包含狠多，有识别的装甲板的颜色，编号，边界框等等，再用for循环将Armor传入Armors，这样Armors就包括很多YOLO识别出来的一个个装甲板的信息
2. 再通过tracker对识别的Armors进行跟踪分类筛选，，，最终从Armors返回一个最优装甲板targets
3. 至于为什么重投影会有这么多的框，是因为Target里的armor_xyza_list()函数，就是通过一个装甲板的位置，结合装甲板的半径，中心，角度，求出另外三个装甲板的每个角点的坐标，然后把所有的交点坐标和框都画出来
4. 作为非科班出身的我对c++的理解还是太浅了，再看代码的时候对类，私有变量的和公有函数变量有了更深的认识，对类的封装性有了更深的理解